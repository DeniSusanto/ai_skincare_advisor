{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build transfer learning model based on the rolled skin patches\n",
    "\n",
    "This is the Step 3: training the deep learning model. In this step, we are using a pre-trained deep learning model in CNTK, [ResNet-152 model](https://github.com/Microsoft/CNTK/tree/master/Examples/Image/Classification/ResNet), to extract features from the training images, and then train a full-connected neural network model on these features, to make the entire deep learning model specific to the acne severity classification domain. The features we extracted are from the last max pooling layer of the pretrained model. The trained full connected neural network is stored for future scoring pipeline.\n",
    "\n",
    "There are two steps here: \n",
    "* Extract features from CNTK pretrained model \n",
    " -   Specify the model name, the last layer name and dimension (model_name, node_name, num_nodes)\n",
    "\n",
    "* Build full connected layers based on the extracted features:\n",
    " -   Build Neural Network regression/classfication model.\n",
    "\n",
    "***Note***: It may take around 1 hour to complete this step, where around 20 minutes to extract features from skin patch images by using pretrained ResNet-152 model as a feature extractor, and around 30 minutes to train the full connected neural network by using the features. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the prerequisites to run this Jupyter notebook:\n",
    "\n",
    "### Skin patch images\n",
    "- The skin patch images need to be stored in the subdirectories corresponding to the labels of their original selfie images. Completing [Step 2. Roll the skin patches and balance classes of images, and move the rolled skin patches to directories based on image labels](../01_DataPre/Step 2. Roll the skin patches and balance classes of images, and move the rolled skin patches to directories based on image labels.ipynb) should make this prerequisite ready. The subdirectories also have rolled skin patches to make the training data cover as much as possible the possible locations of the acne lesions. \n",
    "    \n",
    "### Python and Python libraries\n",
    "- Python 3.5 or later version \n",
    "- CNTK, PIL\n",
    "\n",
    "### CNTK pre-trained model\n",
    "You need to download the pretrained model to the machine. \n",
    "   - [ResNet152\\_ImageNet\\_Caffe.model](https://www.cntk.ai/Models/Caffe_Converted/ResNet152_ImageNet_Caffe.model)\n",
    "   - You can also choose other pretrained models such as inception model, ResNest50 ......\n",
    "   - If you want to look for the layer name and num_nodes after each layer of the pretrained model, run the following code\n",
    "           (\n",
    "           node_outputs = C.logging.get_node_outputs(C.load_model(base_model_file))\n",
    "           for l in node_outputs: \n",
    "                print(\"  {0} {1}\".format(l.name, l.shape))\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Change the following parameters to let the Jupyter Notebook know the locations of the pretrained model, the layer of the pretrained model to extract features from, and the location of the skin patch images under different subdirectories. \n",
    "\n",
    "Later on, the Jupyter Notebook will try to access the model from directory ***pretrained\\_model\\_path\\\\\\\\pretrained\\_model\\_name***, and to access the Clear skin patch images from ***data\\_path\\\\\\\\Clear***, etc. \n",
    "\n",
    "The image\\_height and image\\_width should be consistent with the required image size of the pretrained model. In this work, the pretrained ResNet-152 model requires the input image size to be 224-by-224. Some other pre-trained model might be flexible on the input image size. However, usually, pretrained model requires that the input image to be square shape, i.e., image\\_width = image\\_height. \n",
    "\n",
    "We also specify that we use 80% of the images to be the training images, and the remaining 20% to be the validation images. \n",
    "\n",
    "The parameter ***random\\_seed*** is controlling the randomness of the data splitting and the initialization of the weight matrics of the full connected neural network model. Setting ***random\\_seed=5*** can result in ***RMSE=0.4819*** on the golden set images. Choosing different random seeds might result in higher RMSE on golden set images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = 'ResNet152_ImageNet_Caffe.model'\n",
    "pretrained_model_path = '../models'\n",
    "pretrained_node_name = 'pool5' \n",
    "\n",
    "img_dirs = ['1-Clear', '2-Almost Clear', '3-Mild', '4-Moderate', '5-Severe'] # image labels\n",
    "data_path = '../data/rolled' # image data source\n",
    "\n",
    "image_height = 224 # the height of resize image\n",
    "image_width  = 224 # the width of resize image\n",
    "num_channels = 3 # the RGB image has three chanels\n",
    "random_seed = 5\n",
    "train_ratio = 0.8 # this ratio is used for training and validation in the following models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cntk as C\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import time\n",
    "from cntk import load_model, combine\n",
    "import cntk.io.transforms as xforms\n",
    "from cntk.logging import graph\n",
    "from cntk.logging.graph import get_node_outputs\n",
    "\n",
    "picklefolder_path = os.path.join(data_path, 'pickle') # create a directory pickle to store pickle files for image patches in each \n",
    "                                                      # label directory. Data of all files in each label directory are dumped into\n",
    "                                                      # a single pickle file\n",
    "if not os.path.exists(picklefolder_path):\n",
    "    os.mkdir(picklefolder_path)\n",
    "\n",
    "output_path = '../models'\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "    \n",
    "regression_model_path = os.path.join(output_path, 'cntk_regression.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pretrained model is ResNet152_ImageNet_Caffe.model\n",
      "the selected layer name is pool5 and the number of flatten nodes is 2048\n"
     ]
    }
   ],
   "source": [
    "# define pretrained model location, node name\n",
    "model_file  = os.path.join(pretrained_model_path, pretrained_model_name)\n",
    "loaded_model  = load_model(model_file) # load the pretrained ResNet-152 model.\n",
    "node_in_graph = loaded_model.find_by_name(pretrained_node_name) #find the node name in the pretrained ResNet-152 model\n",
    "output_nodes  = combine([node_in_graph.owner])\n",
    "\n",
    "node_outputs = C.logging.get_node_outputs(loaded_model)\n",
    "for l in node_outputs: \n",
    "    if l.name == pretrained_node_name:\n",
    "        num_nodes = np.prod(np.array(l.shape))\n",
    "        \n",
    "print ('the pretrained model is %s' % pretrained_model_name)\n",
    "print ('the selected layer name is %s and the number of flatten nodes is %d' % (pretrained_node_name, num_nodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features for each class of images and save them into pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path):   \n",
    "    img = Image.open(image_path)       \n",
    "    resized = img.resize((image_width, image_height), Image.ANTIALIAS)  \n",
    "    \n",
    "    bgr_image = np.asarray(resized, dtype=np.float32)[..., [2, 1, 0]]    \n",
    "    hwc_format = np.ascontiguousarray(np.rollaxis(bgr_image, 2)) \n",
    "    \n",
    "    arguments = {loaded_model.arguments[0]: [hwc_format]}    \n",
    "    output = output_nodes.eval(arguments)  #extract the features from the pretrained model, and output\n",
    "    return output\n",
    "\n",
    "def maybe_pickle(folder_path): \n",
    "    dataset = np.ndarray(shape=(len(next(os.walk(folder_path))[2]), num_nodes),\n",
    "                         dtype=np.float16) \n",
    "    num_image = 0        \n",
    "    for file in next(os.walk(folder_path))[2]:\n",
    "        image_path = os.path.join(folder_path, file)\n",
    "        dataset[num_image, :] = extract_features(image_path)[0].flatten()\n",
    "        num_image = num_image + 1\n",
    "    \n",
    "    pickle_filename = folder_path.split('\\\\')[-1] + '.pickle'\n",
    "    pickle_filepath = os.path.join(picklefolder_path, pickle_filename)\n",
    "    if os.path.isfile(pickle_filepath):\n",
    "        os.remove(pickle_filepath)\n",
    "    with open(pickle_filepath, 'wb') as f:\n",
    "        pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL) \n",
    "    \n",
    "    return pickle_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 11317.181208610535 seconds to extract features from skin patch images and dump to pickle files.\n"
     ]
    }
   ],
   "source": [
    "# Here, we go over each subdirectory corresponding to each label, and dump the data of all images in each \n",
    "# subdirectory into a single pickle file\n",
    "start_time = time.time()\n",
    "\n",
    "pickle_names = []\n",
    "    \n",
    "for f in img_dirs:\n",
    "    folder_path = os.path.join(data_path, f)\n",
    "    pickle_names.append(os.path.join(picklefolder_path, maybe_pickle(folder_path)))  # store the pickle file name in pickle_names\n",
    "\n",
    "print(\"It takes %s seconds to extract features from skin patch images and dump to pickle files.\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function that combines training data in each label subdirectory into the same pickle file, so to the validation data.\n",
    "def merge_datasets(pickle_files, train_ratio):\n",
    "    num_classes = len(pickle_files)\n",
    "    num_datasets = [0]*num_classes\n",
    "    for i in range(num_classes):\n",
    "        with open(pickle_files[i], 'rb') as f:\n",
    "            load_data = pickle.load(f)\n",
    "            num_datasets[i] = load_data.shape[0]\n",
    "            \n",
    "    total_datasets = np.sum(num_datasets)\n",
    "    \n",
    "    num_train = [int(round(float(x)*train_ratio)) for x in num_datasets]\n",
    "    num_valid = np.array(num_datasets) - np.array(num_train)\n",
    "   \n",
    "    total_train = np.sum(num_train)\n",
    "    train_dataset = np.ndarray((total_train, num_nodes), dtype=np.float32)\n",
    "    train_labels = np.ndarray(total_train, dtype=np.int32)  \n",
    "    \n",
    "    total_valid = np.sum(num_valid)\n",
    "    valid_dataset = np.ndarray((total_valid, num_nodes), dtype=np.float32)\n",
    "    valid_labels = np.ndarray(total_valid, dtype=np.int32)  \n",
    "    \n",
    "    start_trn, start_val = 0, 0\n",
    "    # the first element in the pickle file is labeled as 1, followd by second element as 2, etc...\n",
    "    np.random.seed(seed=random_seed)\n",
    "    for label, pickle_file in enumerate(pickle_files):  \n",
    "        print (label+1)\n",
    "        print (pickle_file)\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                data_set = pickle.load(f)\n",
    "                np.random.shuffle(data_set) #shuffle the data in each pickle file\n",
    "                \n",
    "                train_data = data_set[0:num_train[label], :] # the first batch goes to training data\n",
    "                train_dataset[start_trn:(start_trn+num_train[label]), :] = train_data\n",
    "                train_labels[start_trn:(start_trn+num_train[label])] = label+1\n",
    "                start_trn += num_train[label]\n",
    "                \n",
    "                valid_data = data_set[num_train[label]:num_datasets[label], :]\n",
    "                valid_dataset[start_val:(start_val+num_valid[label]), :] = valid_data\n",
    "                valid_labels[start_val:(start_val+num_valid[label])] = label+1\n",
    "                start_val += num_valid[label]\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Unable to process data from', pickle_file, ':', e)\n",
    "            raise   \n",
    "            \n",
    "    return train_dataset, train_labels, valid_dataset, valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "../data/rolled\\pickle\\1-Clear.pickle\n",
      "2\n",
      "../data/rolled\\pickle\\2-Almost Clear.pickle\n",
      "3\n",
      "../data/rolled\\pickle\\3-Mild.pickle\n",
      "4\n",
      "../data/rolled\\pickle\\4-Moderate.pickle\n",
      "5\n",
      "../data/rolled\\pickle\\5-Severe.pickle\n",
      "Training: (22656, 2048) (22656,)\n",
      "Validation: (5664, 2048) (5664,)\n"
     ]
    }
   ],
   "source": [
    "# merge all dataset together and divide it into training and validation\n",
    "train_dataset, train_labels, valid_dataset, valid_labels = merge_datasets(pickle_names, train_ratio)\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional layers and train the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1024, 512, 256), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=5, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add regression model which has three hidden layers (1024, 512, 256).\n",
    "# It may take around 30 minutes to train the model. \n",
    "# Default hyperparameters are used here:\n",
    "# L2 penalty: 0.0001\n",
    "# Solver: adam\n",
    "# batch_size: 'auto', = min(200, n_samples) = 200 since n_samples > 200\n",
    "# learning_rate: 'constant'\n",
    "# learning_rate_init: 0.001\n",
    "# max_iter: 200. 200 iterations.\n",
    "# verbose: False. Turn it to True if you want to see the training progress.\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "clf_regr = MLPRegressor(hidden_layer_sizes=(1024, 512, 256), activation='relu', random_state=random_seed)\n",
    "clf_regr.fit(train_dataset, train_labels) #Start training the regression model using the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the validation dataset, and calculate the RMSE on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of images in the validation dataset\n",
    "pred_labels_regr = clf_regr.predict(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RMSE of regression NN is 0.335607\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE on the validation dataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse_regr = sqrt(mean_squared_error(pred_labels_regr, valid_labels))\n",
    "print ('the RMSE of regression NN is %f' % rmse_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained regression model to be used in the scoring pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store regression model\n",
    "regr_model = pickle.dumps(clf_regr)\n",
    "regression_store= pd.DataFrame({\"model\":[regr_model]})\n",
    "regression_store.to_pickle(regression_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
