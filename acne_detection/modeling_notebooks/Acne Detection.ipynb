{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open ../models/shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ae2163025ec4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcntk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcntk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgetPatches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Files & PDF\\COMP4801 - FYP\\code_sources\\acne_detection\\nestle-acne-assessment-master\\getPatches.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPREDICTOR_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mTooManyFaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open ../models/shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join, isfile, splitext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cntk as C\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "from cntk import load_model, combine\n",
    "import cntk.io.transforms as xforms\n",
    "from cntk.logging import graph\n",
    "import getPatches\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path, loaded_model, output_nodes):   \n",
    "    img = Image.open(image_path)       \n",
    "    resized = img.resize((image_width, image_height), Image.ANTIALIAS)  \n",
    "    \n",
    "    bgr_image = np.asarray(resized, dtype=np.float32)[..., [2, 1, 0]]    \n",
    "    hwc_format = np.ascontiguousarray(np.rollaxis(bgr_image, 2)) \n",
    "    \n",
    "    arguments = {loaded_model.arguments[0]: [hwc_format]}    \n",
    "    output = output_nodes.eval(arguments)   \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = 'ResNet152_ImageNet_Caffe.model'\n",
    "pretrained_model_path = '../models'\n",
    "pretrained_node_name = 'pool5' \n",
    "\n",
    "label_mapping = {1: '1-Clear', 2: '2-Almost Clear', 3: '3-Mild', 4: '4-Moderate', 5: '5-Severe'}\n",
    "\n",
    "img_path = '../data/labeled_test_images'\n",
    "test_ground_truth = '../data/test_images_labels.csv' #If None, calculating RMSE on test set will be skipped\n",
    "result_file = '../data/predicted_labels.csv'\n",
    "patch_path = '../data/test_images_patches'\n",
    "regression_model_path = '../models/cntk_regression.dat'\n",
    "eye_cascade_model = '../models/haarcascade_eye.xml'\n",
    "\n",
    "image_height = 224 # Here are the image height and width that the skin patches of the testing selfie are going to be resized to.\n",
    "image_width  = 224 # They have to be the same as the ResNet-152 model requirement.\n",
    "num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFiles = [f for f in listdir(img_path) if isfile(join(img_path, f))]\n",
    "for imagefile in imageFiles:\n",
    "    dim = getPatches.extract_patches(join(img_path, imagefile), {}, {}, patch_path) #extract_patches function is defined in getPatches.py\n",
    "\n",
    "#load the stored regression model\n",
    "read_model = pd.read_pickle(regression_model_path)\n",
    "regression_model = read_model['model'][0]\n",
    "train_regression = pickle.loads(regression_model)\n",
    "#load the stored regression model\n",
    "read_model = pd.read_pickle(regression_model_path)\n",
    "regression_model = read_model['model'][0]\n",
    "train_regression = pickle.loads(regression_model)\n",
    "# get the score value for each patch\n",
    "\n",
    "model_file  = os.path.join(pretrained_model_path, pretrained_model_name)\n",
    "loaded_model  = load_model(model_file)\n",
    "node_in_graph = loaded_model.find_by_name(pretrained_node_name)\n",
    "output_nodes  = combine([node_in_graph.owner])\n",
    "\n",
    "patch_score = dict()\n",
    "for file in next(os.walk(patch_path))[2]:\n",
    "    file_path = os.path.join(patch_path, file)\n",
    "    # extract features from CNTK pretrained model\n",
    "    score_features = extract_features (file_path, loaded_model, output_nodes)[0].flatten()\n",
    "    # score the extracted features using trained regression model\n",
    "    pred_score_label = train_regression.predict(score_features.reshape(1,-1))\n",
    "    patch_score[file] = float(\"{0:.2f}\".format(pred_score_label[0]))\n",
    "# get the max score value among the patches and record the image name\n",
    "image_patch_scores = {}\n",
    "for key in patch_score:\n",
    "    image_id = key.split(\"_landmark\")[0]\n",
    "    image_patch_scores_i = image_patch_scores.get(image_id, {\"patch_name\":[], \"patch_score\":[]})\n",
    "    image_patch_scores_i[\"patch_name\"].append(key)\n",
    "    image_patch_scores_i[\"patch_score\"].append(patch_score[key])\n",
    "    image_patch_scores[image_id] = image_patch_scores_i\n",
    "\n",
    "fp = open(result_file, 'w')\n",
    "fp.write(\"Image_Name, Predicted_Label_Avg, Most_Severe_Patch\\n\")\n",
    "\n",
    "for key in image_patch_scores:\n",
    "    image_name = key.split(\"_landmark\")[0]\n",
    "    max_index = np.argmax(image_patch_scores[key]['patch_score'])\n",
    "    Predicted_Label_Avg = np.mean(image_patch_scores[key]['patch_score'])\n",
    "    Most_Severe_Patch = image_patch_scores[key]['patch_name'][max_index]\n",
    "    fp.write('%s, %.4f, %s\\n'%(image_name, Predicted_Label_Avg, Most_Severe_Patch))\n",
    "\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
